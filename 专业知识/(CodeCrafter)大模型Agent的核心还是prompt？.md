---
title: '(CodeCrafter)大模型Agent的核心还是prompt？'
category: '/小书匠/收集/知乎问答/CodeCrafter/fae26c31a6c41d7a1c8a2d20bbb59367'
slug: 'https://www.zhihu.com/question/628670548/answer/1979655429819746027'
createDate: '2025-12-3 20:57:14'
grammar_mathjax: false
grammar_footnote: false
grammar_ins: false
emoji: 'C'
tags: '大语言模型,Agent'

---


[toc]


# 问题

提问者：**<a href="https://www.zhihu.com/people/mlpod">0xC001</a>**
提问时间: 2023-11-1 17:59:43

目前有什么挑战？

# 回答

回答者： **<a href="https://www.zhihu.com/people/lan-lan-wan">CodeCrafter</a>**
回答时间: 2025-12-3 20:57:14
点赞总数: 518
评论总数: 20
收藏总数: 948
喜欢总数：37

如果这个问题是2023年上半年问的，我会毫不犹豫地告诉你，是的，Prompt就是咒语，就是魔法，谁掌握了Prompt谁就是大法师。那时候我们还在为了怎么让GPT-3.5不胡说八道，在那儿绞尽脑汁地试“Let's think step by step”。

但在现在，马上都要2026年了，如果你还觉得Agent的核心竞争力是Prompt，那你这两年在AI落地的一线战场上，大概率是没怎么把自己弄脏过。

先说结论： **在2025年的今天，Prompt在Agent开发中的权重，已经从原来的90%降到了最多30%。Agent现在的核心，是工作流编排（Workflow Orchestration）、是记忆管理（Memory Management）、是工具生态的接口标准化（Tool Interface Standard），以及最最要命的——自动化评估体系（Automated Evaluation）。** 

Prompt现在充其量就是个前端交互层，是API调用的一个参数而已。

我现在手头正带着团队交付一个企业级的供应链自动决策Agent，咱们就拿这个实战项目当切入点，不管是做技术的还是做产品的，咱们坐下来好好聊聊这事儿。我尽量不拽大词，咱们就聊干货，聊聊我在泥坑里打滚摸出来的经验。

你要是觉得我说得在理，也不用急着赞同，先往下看。

 **一、 为什么Prompt不再是老大了？** 

前两年大家疯狂迷信Prompt Engineering，是因为模型本身的逻辑推理能力不够强，我们需要通过精巧的话术去引导它，甚至可以说是“哄”着模型去干活。

可是现在呢？你看看现在的DeepSeek V3、Claude 4.5 Sonnet（哪怕是半年前的版本）或者OpenAI那边的o1系列后续版本，它们的意图理解能力已经强到离谱了。你现在哪怕给一个很烂的Prompt，模型大概率也能猜到你想干嘛。

我举个最真实的例子。  
以前我们要让Agent去把一段乱七八糟的会议纪要整理成JSON格式，Prompt得写几百字，规定各种字段，还要给Few-Shot（少样本示例），不然输出就给你崩掉。  
现在？我直接把内容丢进去，说一句“转成标准JSON，字段你自己看着办，要符合通用schema”，出来的结果基本就是可用的。

当模型本身的智商提升了，Prompt这种“拐杖”的作用自然就下降了。

但这不代表Agent更好做了。恰恰相反，门槛变高了。因为现在的Agent不再是简单的“聊天机器人”，我们要解决的是复杂任务。

比如我刚才提到的供应链Agent，它的任务是“检测到库存低于安全水位时，自动分析历史销量，预测未来两周需求，对比三家供应商的价格和账期，然后生成一个补货单发给采购经理审批”。

这中间涉及了多少个步骤？

1.  读取ERP库存数据。
2.  调用时序预测模型（这可能都不是LLM干的事，是传统算法干的）。
3.  联网或者查数据库获取供应商报价。
4.  综合决策。
5.  生成报表。
6.  对接飞书或钉钉发消息。

你要是想靠一段几千字的超级Prompt把这所有逻辑都塞给大模型，指望它一次性给你吐出一个完美结果，我只能说你太天真了。大模型一旦上下文过长，那是必定会产生幻觉的，逻辑必定会发生跳跃。

所以，核心变成了 **Flow Engineering（流程工程）** 。

这里我必须要推荐一个东西，如果你还没看过，赶紧去补课。吴恩达老师（Andrew Ng）之前一直在推崇的Agentic Patterns，还有LangChain团队一直在搞的 **LangGraph** 。  
 _资源推荐：去GitHub上搜一下LangGraph的官方cookbook，或者看DeepLearning.AI上关于Agentic Workflow的课程。别光看视频，去跑一下那个代码。你会发现，它不是在写Prompt，它是在写图，在写状态机。_ 

我们在工程落地时发现，一个稳定的Agent，其实是一个由大模型驱动的 **状态机** 。  
我们需要明确地定义：第一步干什么，如果第一步成功了去哪儿，失败了怎么重试，第二步的数据怎么清洗传给第三步。

这才是核心。我们现在的代码库里，Python写的逻辑控制代码（Glue Code），比Prompt的字符数多几十倍。我们是在用代码约束模型的行为，而不是用自然语言去祈祷模型表现良好。

 **二、 现在的挑战到底在哪儿？（这部分全是血泪史）** 

既然Prompt不是挑战了，那我们现在天天加班到底在解决什么问题？我觉得主要集中在这么几个要命的地方。

 **1. 规划（Planning）与执行的脱节** 

大模型特别擅长做计划。你问它“把大象装冰箱分几步”，它给你列得头头是道。  
但是一旦涉及到执行，特别是长链条的执行，它就容易“迷路”。

比如在我们的Agent里，模型规划说：“先去A数据库查用户信息，再去B系统查订单。”  
结果A数据库查出来的信息里，用户名有个特殊字符，模型在生成查询B系统的SQL语句时，直接把这个特殊字符拼进去了，导致SQL注入报错或者查询失败。  
这时候模型往往会陷入死循环，它会反复尝试生成同样的错误SQL，因为它觉得自己的逻辑是对的，是系统在针对它。

这就是 **鲁棒性** 的问题。  
我们在做Agent的时候，大部分精力花在给模型擦屁股上。我们需要写大量的Guardrails（护栏）代码，去校验模型输出的每一步参数是不是合法的。

 **2. 上下文污染与记忆管理的难题** 

2025年了，虽然模型都在吹自己有128K甚至1M的Context Window（上下文窗口），但信我一句话： **Context越长，模型越傻。** 

这就是著名的“Lost in the Middle”（中间迷失）现象。你把几十个PDF扔进去，问它中间某页的一个小细节，它大概率是找不到的，或者会产生幻觉。

在Agent运行过程中，随着步骤越来越多，历史消息（Memory）会迅速堆积。如果我们把所有的报错信息、中间思考过程（Chain of Thought）都塞进上下文，模型很快就会被这些噪音淹没，然后开始胡言乱语。

现在的核心挑战是怎么做 **动态的上下文管理** 。  
我们需要判断，哪些记忆是长期有用的（存向量数据库），哪些是短期任务相关的（放在Context里），哪些是垃圾信息（直接丢弃）。

我们现在的做法是引入了一个“总结Agent”。在主任务进行到关键节点时，会触发一个后台的小模型，把之前的对话记录做个摘要，只保留关键变量（比如用户ID、当前订单号、已确认的需求），把原始对话替换掉。

这技术活儿，比写Prompt难多了。

 **3. 评估的黑盒（Evaluation）** 

这是所有做大模型落地的团队最头疼的问题。  
传统的软件工程，我有单元测试。输入A，输出必须是B，不是B就是Bug。  
Agent不一样。输入A，它可能输出B1，也可能输出B2，虽然措辞不一样，但意思都对。你怎么测？

更可怕的是，Agent的错误往往是隐性的。  
比如那个供应链Agent，它做出了一个决策：“建议补货500件”。  
这个决策对不对？也许算法算出来是520件，它说是500件，好像也能接受。但如果它依据的逻辑是错的（比如它把上个月的数据当成了这个月的），但结果碰巧蒙对了，这种Bug怎么测？

现在行业里没有特别完美的解决方案。我们目前用的是 **LLM-as-a-Judge** 。就是用一个更强的模型去评估小模型或者Agent的执行过程。

 **三、 从Prompt Engineering到DSPy：范式的转移** 

既然聊到了Prompt不是核心，那总得有个东西来替代它吧？  
如果你还在手动调整Prompt，比如把“You are a helpful assistant”改成“You are an expert data scientist”，那你真的得看看 **DSPy** 这个项目了。

这是斯坦福大学搞的一个框架。它的核心理念极其超前： **Prompt不应该由人来写，应该由模型自己优化。** 

在DSPy里，你只需要定义任务的逻辑（Signature），比如“输入是问题，输出是答案”，然后你需要准备一些高质量的数据集。DSPy会自动帮你在后台把这个Prompt“编译”出来。它会自动尝试各种Few-Shot的组合，自动调整指令，直到在你的测试集上效果达到最优。

这才是未来。  
我们团队现在很多模块已经不再手写Prompt了，而是写DSPy的Module，然后跑优化器。这就好比以前我们写汇编语言（手写Prompt），现在我们写C++（DSPy），编译器帮我们生成汇编。

 **四、 真实场景里的那些坑（这些都是学费换来的）** 

为了让大家更有体感，我再讲个具体的场景。我们之前做过一个给保险公司用的理赔核查Agent。

 **初始阶段（Prompt思维）：**   
我们写了一个超级长的System Prompt，大概有3000个token。里面详细规定了车险理赔的各种规则：“如果是单方事故，要检查现场照片；如果是双方事故，要看交警责任认定书……”  
结果上线后灾难现场。  
用户传了一张照片，比较模糊。Agent直接幻觉出了一张责任认定书的内容，还言之凿凿地拒绝了理赔。  
为什么？因为Prompt太长，指令冲突，模型为了“对齐”你的指令（尽职尽责地分析），在信息不足时强行脑补了信息。

 **进阶阶段（Agentic Flow思维）：**   
我们把这个大Prompt拆碎了。  
变成了三个独立的Agent：

1.   **材料初审Agent** ：只负责看图片清晰度，分类图片类型。如果不清晰，直接返回“请重传”，绝不进入下一环节。
2.   **规则提取Agent** ：把用户的文字描述和结构化的理赔规则库进行RAG检索，找到适用的那几条条款。
3.   **最终裁决Agent** ：拿着清晰的材料和筛选后的条款，做最后判断。

这三个Agent之间是用 **代码逻辑** 串起来的。  
比如，代码规定：`if 材料初审Agent.result == "不清晰": return "请重传"`。  
这根本不需要模型去判断，代码逻辑是最可靠的。

你看，这里的核心是Prompt吗？不是。那三个Agent用的Prompt都极其简单，大概就几行字。核心是我们拆解问题架构的能力，是我们设计这个Workflow的功力。

眼瞅着要跨年了，给各位同行或者想入行的朋友们几个实在的建议。

 **1. 别再迷恋“通才”模型，关注“专才”配合。**   
以前我们总想这一个模型把所有事干了。现在趋势是 **Multi-Agent System（多智能体系统）** 。一个负责写代码，一个负责运行代码，一个负责提意见。  
微软的 **AutoGen** ，还有我刚才说的LangGraph，都是在往这个方向走。你要学的不是怎么写Prompt，而是怎么让两个AI吵架（辩论），然后吵出一个正确结果。

 **2. 掌握结构化输出是基本功。**   
别再让模型输出自然语言了，除非是给最终用户看的。在Agent内部流转的数据，必须是JSON，必须是Pydantic对象。  
现在OpenAI的Structured Outputs功能，还有很多开源模型的Function Calling能力，必须练得滚瓜烂熟。这是Agent能接入传统IT系统的桥梁。

 **3. 这里的“数据”变了。**   
以前做算法，数据是训练集。现在做Agent，数据是 **SOP（标准作业程序）** 。  
你要想做一个好的HR Agent，你缺的不是Prompt，你缺的是你们公司那本厚厚的员工手册，以及过去三年HR处理各种奇葩请假理由的真实案例。  
把这些SOP转化成Agent能理解的Tool或者是Knowledge Base，这才是壁垒。

 **4. 所有的Agent最后都是代码工程问题。**   
不要因为它是AI，就忽略了软件工程的原则。版本控制、单元测试、日志监控、灰度发布，这些传统后端开发的东西，在Agent开发里一个都不能少。  
甚至更重要。因为代码错了会报错，Agent错了它会一本正经地胡说八道。

如果你想真正理解agent技术是怎么落地的，那 **肯定是要去关注业内最顶尖的公司的实际落地场景** 。

字节就是一个很好的关注对象，因为它的版图足够大，所以它的agent手册就可以覆盖agent从底层技术（ **大模型、工具调用、API 集成、架构设计** ）到各种泛业务场景（ **办公、电商、内容创作、教育** ）的全链路案例。

[字节内部Agent实践手册.pdf](https://mp.weixin.qq.com/s/EPG7UNdBvlQmlv3TtSm80A)

这个手册里面字节的agent案例就可以有一套完整的框架和思路，从而收获一个比较全景的视角。比如 **飞书里的智能办公**  agent怎么自动排会生成会议纪要； **抖音电商的agent怎么实现库存监控、智能客服、定价优化** ；内容创作的agent怎么辅助创作者构思脚本和选素材； **教育场景的agent 怎么给学生定制学习计划和实时答疑** 。

回到开头那个问题。  
大模型Agent的核心还是Prompt吗？  
绝对不是。

Prompt在当下，就像是写代码里的变量命名。变量名起得好，代码可读性确实高，但光靠变量名起得好，写不出淘宝和微信。  
系统的架构设计、数据流转的逻辑、异常情况的处理、以及你在这个垂直领域沉淀下来的Know-How（行业认知），这些被封装在Workflow和Tool里的东西，才是你真正的护城河。

别再在Prompt上雕花这事儿上浪费太多时间了。  
去学LangGraph，去学DSPy，去搞定RAG的准确率，去把你们业务的SOP代码化。  
这才是通往2026年高阶玩家的门票。

这行变化太快，我也在焦虑地学。咱们共勉。  
觉得有用的，动动手指点个赞，收藏起来，哪怕是当个反面教材，过半年再来看看我说得准不准。

  

原文地址：[(CodeCrafter)大模型Agent的核心还是prompt？](https://www.zhihu.com/question/628670548/answer/1979655429819746027) 


